"""
ML ÐœÐ˜ÐšÐ ÐžÐ¡Ð•Ð Ð’Ð˜Ð¡ Ð”Ð›Ð¯ Ð¢ÐžÐ Ð“ÐžÐ’ÐžÐ“Ðž Ð‘ÐžÐ¢Ð
Flask API Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹ ML Ð¼Ð¾Ð´ÐµÐ»Ð¸
"""
from flask import Flask, request, jsonify
from flask_cors import CORS
import joblib
import numpy as np
import os
from datetime import datetime

app = Flask(__name__)
CORS(app)  # Ð Ð°Ð·Ñ€ÐµÑˆÐ°ÐµÐ¼ CORS Ð´Ð»Ñ Ð²ÑÐµÑ… Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²

# ÐŸÑƒÑ‚ÑŒ Ðº Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼
MODEL_PATH = os.getenv('MODEL_PATH', '../ml_model.pkl')
SCALER_PATH = os.getenv('SCALER_PATH', '../scaler.pkl')

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ñ€Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ðµ
model = None
scaler = None

try:
    if os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH):
        model = joblib.load(MODEL_PATH)
        scaler = joblib.load(SCALER_PATH)
        print(f"âœ… ML Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð¸Ð· {MODEL_PATH}")
    else:
        print(f"âš ï¸ ML Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð² {MODEL_PATH}")
except Exception as e:
    print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")


@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model is not None,
        'timestamp': datetime.now().isoformat()
    })


@app.route('/predict', methods=['POST'])
def predict():
    """
    ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ ML Ð¼Ð¾Ð´ÐµÐ»Ð¸
    
    ÐžÐ¶Ð¸Ð´Ð°ÐµÑ‚ JSON:
    {
        "features": [feature1, feature2, ...],
        "ohlcv": [[timestamp, open, high, low, close, volume], ...]
    }
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    {
        "prediction": 0 or 1,
        "confidence": 0.0-1.0,
        "signal": "BUY" or "SELL" or "HOLD"
    }
    """
    if model is None or scaler is None:
        return jsonify({
            'error': 'ML model not loaded',
            'prediction': 0.5,
            'signal': 'HOLD'
        }), 503
    
    try:
        data = request.get_json()
        
        if 'features' not in data:
            return jsonify({'error': 'Missing features'}), 400
        
        features = np.array(data['features']).reshape(1, -1)
        
        # ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€ÑƒÐµÐ¼ features
        features_scaled = scaler.transform(features)
        
        # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
        prediction = model.predict(features_scaled)[0]
        confidence = model.predict_proba(features_scaled)[0][prediction]
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑÐ¸Ð³Ð½Ð°Ð»
        signal = 'HOLD'
        if prediction == 1 and confidence > 0.6:
            signal = 'BUY'
        elif prediction == 0 and confidence > 0.6:
            signal = 'SELL'
        
        return jsonify({
            'prediction': int(prediction),
            'confidence': float(confidence),
            'signal': signal,
            'timestamp': datetime.now().isoformat()
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/train', methods=['POST'])
def train():
    """
    ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
    
    ÐžÐ¶Ð¸Ð´Ð°ÐµÑ‚ JSON:
    {
        "ohlcv": [[timestamp, open, high, low, close, volume], ...],
        "epochs": 50
    }
    """
    # TODO: Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    return jsonify({
        'message': 'Training not implemented yet'
    }), 501


if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('DEBUG', 'False').lower() == 'true'
    
    print(f"ðŸš€ ML Service starting on port {port}")
    print(f"ðŸ“Š Model path: {MODEL_PATH}")
    
    app.run(host='0.0.0.0', port=port, debug=debug)
